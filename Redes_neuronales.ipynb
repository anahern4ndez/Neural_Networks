{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "Se realizó el entrenamiento del modelo con los datos del set de fashion-mnist, en el cual se tienen imágenes de 10 tipos distintos de prendas de ropa, representadas numéricamente en 784(28x28) pixeles. Para el entrenamiento se tomaron 60,000 datos, traducidos a una sola matriz de 60,000x784. En el repositorio de este notebook se incluye neural_networks.py, ahí se realizó el entrenamiento del modelo con el training set, el cual se guardó en el archivo 'data/training_model'. Debido al largo tiempo que se tomó en finalizar el entrenamiento, no se repetirá en este notebook pero el código sí quedará aquí. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de funciones \n",
    "\n",
    "A continuación se definirán las funciones necesarias para la implementación de la red neuronal. Estas se encuentran archivadas en el módulo de 'back_propagation.py' (en donde también se encuentra una mayor explicación de los parámetros, los valores devueltos y comentarios en las secciones relevantes), por lo que solo se describirá aquí las funciones más relevantes y no se correrán aquí ya que se realiza al importar dicho módulo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoide\n",
    "\n",
    "Esta función está descrita por el siguiente modelo matemático: $$ S(x) = \\frac{1}{1 + e^{-z}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(thetas, X):\n",
    "    a = [X] \n",
    "    for i in range(len(thetas)): \n",
    "        a.append(\n",
    "            sigmoid(\n",
    "                np.matmul(\n",
    "                    np.hstack((\n",
    "                        np.ones(len(a[i])).reshape(len(a[i]), 1),\n",
    "                        a[i]\n",
    "                    )),\n",
    "                    thetas[i].T\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(f_thetas, shapes, X, Y):\n",
    "    m, layers = len(X), len(shapes) + 1\n",
    "    thetas = inflate_matrixes(f_thetas, shapes)\n",
    "    a = feed_forward(thetas, X)\n",
    "    deltas = [ *range(layers -1), a[-1] - Y ] \n",
    "    for i in range(layers-2, 0, -1):\n",
    "        deltas[i] = np.matmul(\n",
    "            deltas[i+1],\n",
    "            (thetas[i])[:, 1:]\n",
    "        ) * (a[i] * (1 - a[i]))\n",
    "    gradient = []\n",
    "    for i in range(layers-1):\n",
    "        gradient.append((np.matmul(\n",
    "            deltas[i+1].T, \n",
    "            np.hstack(( \n",
    "                        np.ones(len(a[i])).reshape(len(a[i]), 1),\n",
    "                        a[i]\n",
    "                    ))\n",
    "        )) / m)\n",
    "    return flatten_matrixes(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de costo \n",
    "\n",
    "La función de costo se realiza haciendo la sumatoria de diferencias entre el valor esperado y el valor proveído por cada neurona, en cada capa. El modelo matemático es el siguiente: \n",
    "$$ J(\\theta) =  \\frac{-1}{m}\\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^i log(h_\\theta (x^i)_k)  +  (1-y_k^i)log(1 - h_\\theta (x^i)_k)$$\n",
    "En donde:\n",
    "\n",
    "K: cantidad de capas \n",
    "\n",
    "m: cantidad de datos ingresados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost(flat_thetas, shapes, X, Y):\n",
    "    # obtener predicciones \n",
    "    a = feed_forward(\n",
    "        inflate_matrixes(flat_thetas, shapes),\n",
    "        X\n",
    "    )\n",
    "    return -(Y * np.log(a[-1]) + (1 - Y) * np.log(1 - a[-1])).sum() / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import de todas las librerías necesarias \n",
    "from back_propagation import * # en este modulo se tienen las funciones para la red neuronal \n",
    "import numpy as np\n",
    "import mnist_reader\n",
    "import scipy.optimize as optimize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "El siguiente código fue realizado para la parte de training del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import \n",
    "X_train, y_train = mnist_reader.load_mnist('data/', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train / 255.0\n",
    "m,n = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establecimiento de constantes\n",
    "HIDDEN_LAYER = 90 # Cantidad de neuronas en la capa oculta\n",
    "FINAL_LAYER = 10 # cantidad de neuronas en la capa final \n",
    "theta_shapes = np.array([\n",
    "    [ HIDDEN_LAYER, n+1 ],\n",
    "    [ FINAL_LAYER, HIDDEN_LAYER+1 ]\n",
    "])\n",
    "theta_shapes_list = [(HIDDEN_LAYER, n+1), (FINAL_LAYER, HIDDEN_LAYER+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la función de costo y back_propagation requiere comparación de matrices de predicción y valores teóricos (Y), por lo\n",
    "# que se debe traducir el vector de datos teóricos en una matriz 60,000x10\n",
    "Y = np.zeros((X.shape[0], FINAL_LAYER))\n",
    "for i in range(m):\n",
    "    Y[i][y_train[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código se presentará solo para demostrar cómo se realizó el entrenamiento, pero no se ejecutará aquí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generacion de matrices de transicion (aplanadas) random \n",
    "flat_thetas = flatten_matrixes([\n",
    "    np.random.rand(*theta_shape) / 255.0\n",
    "    for theta_shape in theta_shapes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimización de modelo \n",
    "result = optimize.minimize(\n",
    "    fun=nn_cost,\n",
    "    x0=flat_thetas,\n",
    "    args=(theta_shapes, X, Y),\n",
    "    method='L-BFGS-B',\n",
    "    jac=back_propagation,\n",
    "    options={\n",
    "        'disp': True, \n",
    "        'maxiter': 1000, \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload de modelo a un archivo\n",
    "model_filename = 'data/trained_model'\n",
    "model_file = open(model_filename, 'wb')\n",
    "# writing model \n",
    "pickle.dump(np.asarray(result.x), model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se hará el load del modelo optimizado por el código anterior y se obtendrá su porcentaje de accuracy para los datos de training. El accuracy se obtuvo de la siguiente manera: $$ accuracy = \\frac{\\# hits}{\\# instances}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'data/trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open(model_filename, 'rb')\n",
    "flat_thetas = pickle.load(open(model_filename, 'rb'))\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inflar las matrices flattened que vienen del modelo cargado \n",
    "result_thetas = inflate_matrixes(flat_thetas, theta_shapes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtener la matriz de prediccion (ultima que da el feed forward)\n",
    "prediction = feed_forward(result_thetas, X)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY: 98.85666666666667%\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(prediction, y_train)\n",
    "print(\"TRAINING ACCURACY: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se obtendrá el porcentaje de accuracy por clase. Las clases son como sigue:\n",
    "\n",
    "0:\tT-shirt/top\n",
    "\n",
    "1:\tTrouser\n",
    "\n",
    "2:\tPullover\n",
    "\n",
    "3:\tDress\n",
    "\n",
    "4:\tCoat\n",
    "\n",
    "5:\tSandal\n",
    "\n",
    "6:\tShirt\n",
    "\n",
    "7:\tSneaker\n",
    "\n",
    "8:\tBag\n",
    "\n",
    "9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class = get_accuracy_by_class(prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 98.60%\n",
      "Clase 1: 99.88%\n",
      "Clase 2: 96.78%\n",
      "Clase 3: 98.53%\n",
      "Clase 4: 98.13%\n",
      "Clase 5: 100.00%\n",
      "Clase 6: 97.13%\n",
      "Clase 7: 99.98%\n",
      "Clase 8: 99.58%\n",
      "Clase 9: 99.93%\n"
     ]
    }
   ],
   "source": [
    "for value in accuracy_per_class:\n",
    "    print('Clase {}: {:.2f}%'.format(accuracy_per_class.index(value), value * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Ahora se realizará la predicción para los datos de testing. Para este set se tomaron 10,000 del archivo 't10k' proveído por el creador de fashion-mnist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtener la matriz de prediccion (ultima que da el feed forward)\n",
    "X = X_test / 255.0\n",
    "m,n = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_shapes = np.array([\n",
    "    [ HIDDEN_LAYER, n+1 ],\n",
    "    [ FINAL_LAYER, HIDDEN_LAYER+1 ]\n",
    "])\n",
    "theta_shapes_list = [(HIDDEN_LAYER, n+1), (FINAL_LAYER, HIDDEN_LAYER+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_thetas = inflate_matrixes(flat_thetas, theta_shapes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = feed_forward(result_thetas, X)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 85.5%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = get_accuracy(prediction, y_test)\n",
    "print(\"TEST ACCURACY: {}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_per_class = get_accuracy_by_class(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 79.50%\n",
      "Clase 1: 96.60%\n",
      "Clase 2: 75.30%\n",
      "Clase 3: 84.10%\n",
      "Clase 4: 77.40%\n",
      "Clase 5: 94.90%\n",
      "Clase 6: 62.70%\n",
      "Clase 7: 94.40%\n",
      "Clase 8: 95.30%\n",
      "Clase 9: 94.80%\n"
     ]
    }
   ],
   "source": [
    "for value in test_accuracy_per_class:\n",
    "    print('Clase {}: {:.2f}%'.format(test_accuracy_per_class.index(value), value * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En su mayoría, el modelo tiene un buen desempeño, con un 85.5% de aciertos en general. Los datos que más le cuesta trabajo predecir y clasificar correctamente son aquellos que pertenecen a las clases 6, 4, 2, y 0, que son las camisas, los abrigos, los pullovers y t-shirts, respectivamente. La razón por la cual se confunde tanto puede ser debido a que estas prendas en específico tienden a parecerse (a veces hasta uno de humano tiene dificultades en diferenciar abrigos y suéteres y pullovers o camisas - shirts - y t-shirts), por lo que es comprensible que el algoritmo se confunda y clasifique un objeto en otra clase parecida. Lo importante es que sabe diferenciar bastante bien entre objetos que son fácilmente separables, como bolsas, sandalias, sneakers y botitas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
